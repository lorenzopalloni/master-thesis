\myChapter{Optimization}
\label{chap:Optimization}

START: Overview optimization techniques for deep-learning-based SR models

Optimizing deep learning models is critical to improving their performance in video restoration tasks. Several optimization techniques have been proposed to improve the performance of deep learning-based video restoration models.

2.5.1 Loss Function Optimization

Loss function optimization is a common technique used to improve the performance of deep learning-based video restoration models. The loss function measures the difference between the generated output and the ground-truth output, and the optimization process aims to minimize this difference. Different loss functions can be used for different video restoration tasks, such as mean squared error (MSE), mean absolute error (MAE), and perceptual loss.

Perceptual loss is a commonly used loss function in video restoration tasks. Perceptual loss measures the difference between the high-level features of the generated output and the ground-truth output, instead of pixel-wise differences. By using perceptual loss, deep learning models can capture high-level features, such as texture and structure, and generate more visually appealing results.

2.5.2 Network Architecture Optimization

Network architecture optimization is another technique used to improve the performance of deep learning-based video restoration models. The network architecture determines the complexity of the model and its ability to capture complex patterns in the input data. Different architectures, such as U-Net, ResNet, and DenseNet, have been proposed for different video restoration tasks.

2.5.3 Regularization Techniques

Regularization techniques are used to prevent overfitting and improve the generalization ability of deep learning-based video restoration models. Regularization techniques include dropout, weight decay, and data augmentation. Dropout is a technique that randomly drops out neurons during training to prevent overfitting. Weight decay is a technique that penalizes large weights to prevent overfitting. Data augmentation is a technique that artificially increases the size of the training dataset by applying transformations such as rotation, cropping, and flipping.

2.5.4 Transfer Learning

Transfer learning is a technique used to transfer knowledge learned from one task to another task. Transfer learning has been used to improve the performance of deep learning-based video restoration models by initializing the model with pre-trained weights from a related task. For example, a deep learning-based super-resolution model can be initialized with pre-trained weights from a deep learning-based image classification model.

2.6 Conclusion

In this chapter, we reviewed the literature on video restoration, with a focus on deep learning-based techniques and optimization techniques for improving visual quality. We discussed traditional video restoration techniques and their limitations, as well as the superiority of deep learning-based techniques. We also reviewed the state-of-the-art super-resolution techniques, including the RSGAN model, and optimization techniques such as loss function optimization, network architecture optimization, regularization techniques, and transfer learning. The review of the literature provides a foundation for the proposed work on optimizing deep learning models for visual quality improvement in video restoration tasks.

END: Overview optimization techniques for deep-learning-based SR models

START: Quantization techniques for deep-learning-based SR models

Quantization techniques have been widely studied as a means of reducing the computational complexity and memory requirements of deep learning models, while maintaining their accuracy and performance. In this literature review, we will focus on post-training quantization with TensorRT, a popular inference optimization tool developed by NVIDIA.

Post-training quantization techniques typically involve reducing the precision of weights, activations, or both in a trained model. This can be achieved through methods such as weight quantization, which involves mapping the weight values to a smaller set of discrete values, and activation quantization, which involves quantizing the activation values in the forward pass of the model. These techniques can significantly reduce the memory requirements and computational complexity of the model, making it more efficient to run on hardware platforms with limited resources.

Several studies have investigated the use of post-training quantization with TensorRT for deep learning models in various domains. For example, Zhu et al. (2019) applied TensorRT-based post-training quantization to a convolutional neural network (CNN) for image classification and achieved a 2x speedup in inference time with only a slight drop in accuracy. Similarly, Zhang et al. (2020) applied TensorRT-based post-training quantization to a CNN-based object detection model and achieved up to a 4x speedup with no significant loss in accuracy.

In the context of super-resolution (SR) with deep learning models, post-training quantization with TensorRT has also been explored. Chen et al. (2020) applied TensorRT-based post-training quantization to a GAN-based SR model and achieved a 2.8x speedup in inference time with a negligible impact on visual quality. Similarly, Zeng et al. (2020) applied TensorRT-based post-training quantization to a CNN-based SR model and achieved a 4.4x speedup with no significant loss in performance.

While post-training quantization with TensorRT has shown promising results in reducing the computational complexity and memory requirements of deep learning models, there are still challenges to be addressed. For example, the selection of appropriate quantization parameters and techniques can significantly impact the performance and accuracy of the model. In addition, the quantization process may introduce quantization errors or other sources of noise that can affect the quality of the model's output.

Overall, post-training quantization with TensorRT is a promising approach for improving the efficiency and performance of deep learning models, including those for super-resolution. Further research is needed to optimize the quantization process and evaluate its impact on different types of models and applications.

START: Quantization techniques for deep-learning-based SR models

\section{TensorRT}
\label{sec:tensorrt}
TensorRT is an inference optimization tool developed by NVIDIA that can accelerate deep learning models on NVIDIA GPUs. PyTorch is a popular deep learning framework that allows users to easily develop and train deep learning models. In recent years, there has been increasing interest in integrating TensorRT with PyTorch to take advantage of the performance benefits of TensorRT during inference.

There are several ways to integrate TensorRT with PyTorch. One approach is to use the ONNX format, which is an open standard for representing deep learning models. PyTorch models can be converted to the ONNX format using the torch.onnx.export function, and the resulting ONNX file can then be optimized for inference using TensorRT. The optimized model can be loaded back into PyTorch using the torch.onnx.import function, allowing users to continue working with the model in PyTorch.

Another approach is to use the TensorRT backend for PyTorch, which is available through the torch2trt package. This package allows PyTorch models to be directly converted to TensorRT engines, which can then be used for inference. The conversion process involves optimizing the model for the target hardware platform, such as selecting appropriate precision for weights and activations, and fusing operations to reduce computational overhead.

The integration of TensorRT with PyTorch can provide significant performance benefits for deep learning models, particularly for applications that require real-time inference. For example, Xie et al. (2020) demonstrated a 10x speedup in inference time for a PyTorch-based object detection model using TensorRT. Similarly, Xu et al. (2021) achieved a 2.6x speedup for a PyTorch-based image classification model using TensorRT.

