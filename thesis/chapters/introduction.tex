\myChapter{Introduction}
\label{chap:Introduction}

Super-resolution (SR) with deep learning models has achieved remarkable success in recent years, but the computational complexity of these models is a significant bottleneck for real-world applications. One promising approach to reducing the computational cost of deep learning models is through quantization techniques, which aim to represent the weights and activations of the model with fewer bits without significant loss of accuracy. Quantization can lead to significant improvements in model inference speed and memory usage, making it a highly attractive approach for deploying SR models on resource-constrained devices.

This Master's thesis focuses on investigating the effectiveness of quantization techniques for improving the speed and efficiency of deep learning models for SR. The research will involve an in-depth review of the literature on quantization techniques for deep learning models and their application in the field of SR. The thesis will also explore the implementation and evaluation of post-training quantization using TensorRT, an NVIDIA SDK for high-performance deep learning inference. 

The ultimate goal of this research is to maintain the quality of full-precision SR models while improving inference speed with state-of-the-art quantization techniques.

The results of this thesis are expected to contribute to the knowledge and the capability on developing more practical and efficient SR models, which can potentially be deployed in various real-world applications, such as mobile devices, embedded systems, and IoT devices.

