\myChapter{Background}
\label{chap:Background}

In this chapter, the existing literature on methods to address video restoration is reviewed, with a focus on recent deep learning models for single-image super-resolution that are closely related to this thesis.

% The first widely adopted CNN-based SR model was the Super-Resolution Convolutional Neural Network (SRCNN) proposed by Dong et al. (2014). SRCNN utilizes a three-layer CNN architecture with patch-based training to learn an end-to-end from low-resolution to high-resolution images. Since then, many variants of CNN-based SR models have been proposed, including VDSR (Kim et al., 2016), EDSR (Lim et al., 2017), and RCAN (Zhang et al., 2018), among others. These models typically have deeper and wider architectures than SRCNN and incorporate various techniques such as residual connections, feature normalization, and attention mechanisms to improve SR performance.

Dong et al. \cite{dong2014learning} present the SRCNN model using convolutional neural networks for single-image super-resolution, while Kim et al. introduce VDSR \cite{kim2016accurate} and DRCN \cite{kim2016deeply} models with a residual learning framework \cite{he2016deep}. Dong et al. and Shi et al. efficiently map low-resolution to high-resolution images using deconvolution and sub-pixel convolution layers, respectively. LatticeNet, LapSRN, MemNet, SRDenseNet, and RDN are other lightweight and efficient SR models. Haris et al. and DSRN focus on iterative up-sampling and down-sampling and dual-state recurrent networks, respectively. MSRN and RFA exploit image features, while attention mechanisms and GANs, including SRGAN, EnhanceNet, ESRGAN, SPSR, and SRFlow, are also used to improve image quality.

Generative Adversarial Networks (GANs) have been employed in various methods. Galteri et al. use adversarial training to remove artifacts from lossy compression algorithms for images and videos, training models with larger batches and utilizing an ensemble of networks. They also address real-time artifact removal using MobileNetV2-inspired generators with depth-wise separable convolutions. Mameli et al. apply the no-GAN approach for compression artifact removal and super-resolution, using pre-training and few GAN training iterations. Kaneko et al. introduce BNCR-GAN, an architecture that removes noise, compression artifacts, and blurring artifacts by combining three models and using adaptive consistency losses.

Pourreza et al. propose a GAN-based quality enhancement method to address accuracy loss in action recognition tasks caused by video compression, using a frame-recurrent strategy. Yu et al. develop VR-GAN for HEVC compression-generated artifact removal, operating at the inter-frame level and using flow estimation for coherence. He et al. enhance HEVC compressed videos using adversarial loss combined with L1 loss, employing a residual network generator.

Galteri et al. present a full pipeline architecture featuring semantic deep encoding and decoding, with a semantic mask for each frame to allocate more bits to semantically interesting content. The decoding side uses a Relativistic GAN and a segmentation-aware loss.

Video super-resolution presents a more significant challenge than single-image super-resolution due to the need to effectively predict both content and motion. Motion information plays a crucial role in restoring high-resolution frames from multiple low-resolution images. The most successful approaches in multi-image super-resolution (MISR) include sliding-window techniques and recurrent methods.

Sliding-window techniques can potentially restore more high-resolution details of target frames since they have access to more visual information. However, these methods must account for motion content between frames to achieve high-quality super-resolution results. On the other hand, recurrent neural networks, which have been widely used for various vision tasks like classification, detection, and segmentation, can process inputs of any length by sharing model weights across time. These recurrent models are capable of accounting for long-range dependence among pixels, making them an excellent choice for video super-resolution tasks. In recent years, numerous video super-resolution models have been developed based on recurrent neural networks, showcasing their effectiveness in this domain.

 
% GAN-based SR models have also gained popularity in recent years. SRGAN (Ledig et al., 2017) is a notable example that utilizes a GAN architecture to generate high-resolution images from low-resolution inputs. The generator network of SRGAN is trained to produce high-resolution images that are perceptually similar to the ground truth images, while the discriminator network is trained to distinguish between the generated and ground truth images. Since then, several GAN-based SR models have been proposed, including ESRGAN (Wang et al., 2018) and SRFBN (Liu et al., 2019).

