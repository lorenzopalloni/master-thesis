\myChapter{Experiments}
\label{chap:Experiments}

% \section{TODOs}
% \begin{itemize}
% 
% \item{increase precision of times table}
% \item{decrease precision of metrics table and add VMAF}
% \item{make figure captions shorter and describe such images}
% \item{adjust figures positioning}
% \item{include table to showcase memory consumption differences}
% 
% \item{explain the following:
%   From \cref{tab:tab1}, INT8 models outperform full-precision performance on non-perceptual metrics, such as SSIM, PSNR, MS-SSIM. This is probably due to the fact that outputs from lower precision models are naturally more blurry than the ones from full-precision models.
% }
% 
% \item{explain the following:
%   Images generated by plain PyTorch implementations and their FP32 versions differ in quality most likely because they differ at the end of their architectures, since they use respectively bicubic and bilinear interpolation techniques to scale up the input low-quality image to allow the models to learn residual values between low- and high-quality images.
% }
% \end{itemize}


In this chapter, we will showcase various experiments and their corresponding results, highlighting the inference speed and image quality. We will utilize both the basic PyTorch implementations of UNet and SRUNet, as well as their compiled counterparts with TensorRT, which will be configured with different precisions for weights/activations, namely FP32, FP16, and INT8.

\section{Quantitative Results}
\label{sec:quantitative-results}

For each model variation, \cref{tab:metrics} reports the average value of each metric, along with its standard deviation. Higher values of these metrics indicate better image quality. The table shows that the UNet models have higher values for LPIPS and BRISQUE, but lower values for PSNR compared to the SRUNet models. However, the SSIM and MS-SSIM metrics are similar for both models. Additionally, there is a notable difference between the performance of the plain PyTorch implementations and their TensorRT counterparts for both UNet and SRUNet models, especially for LPIPS, BRISQUE, and PSNR metrics.

\begin{table*}[t]
\begin{tabular}{llll}
\toprule
{} &              LPIPS &              DISTS &             BRISQUE \\
\midrule
UNet        &  0.28975 ± 0.01377 &  0.12225 ± 0.00671 &  31.13719 ± 1.16896 \\
UNet-FP32   &  0.28975 ± 0.01377 &  0.12225 ± 0.00671 &  31.13733 ± 1.16844 \\
UNet-FP16   &  0.28976 ± 0.01377 &  0.12226 ± 0.00671 &  31.13834 ± 1.16908 \\
UNet-INT8   &  0.30414 ± 0.01371 &  0.12829 ± 0.00662 &  29.68486 ± 1.01377 \\
SRUNet      &  0.31106 ± 0.01505 &  0.17172 ± 0.00472 &  27.37380 ± 3.57055 \\
SRUNet-FP32 &  0.31106 ± 0.01505 &  0.17172 ± 0.00472 &  27.37365 ± 3.56975 \\
SRUNet-FP16 &  0.31108 ± 0.01505 &  0.17172 ± 0.00472 &  27.37904 ± 3.57393 \\
SRUNet-INT8 &  0.30677 ± 0.01366 &  0.17217 ± 0.00442 &  26.15459 ± 3.22726 \\
\bottomrule
\end{tabular}
\caption{Perceptual metrics evaluations over 60 frames (mean $\pm$ standard deviation).}
\label{tab:metrics}
\end{table*}

\begin{table*}[t]
\begin{tabular}{llll}
\toprule
{} &               SSIM &            MS-SSIM &                PSNR \\
\midrule
UNet        &  0.89522 ± 0.00842 &  0.85169 ± 0.00673 &  21.65057 ± 0.12692 \\
UNet-FP32   &  0.89522 ± 0.00842 &  0.85169 ± 0.00673 &  21.65057 ± 0.12692 \\
UNet-FP16   &  0.89522 ± 0.00842 &  0.85168 ± 0.00673 &  21.65064 ± 0.12693 \\
UNet-INT8   &  0.89412 ± 0.00840 &  0.85082 ± 0.00672 &  21.63878 ± 0.12864 \\
SRUNet      &  0.88938 ± 0.00840 &  0.84569 ± 0.00616 &  21.36702 ± 0.12477 \\
SRUNet-FP32 &  0.88938 ± 0.00840 &  0.84569 ± 0.00616 &  21.36702 ± 0.12477 \\
SRUNet-FP16 &  0.88937 ± 0.00840 &  0.84568 ± 0.00616 &  21.36712 ± 0.12479 \\
SRUNet-INT8 &  0.88820 ± 0.00840 &  0.84421 ± 0.00616 &  21.33201 ± 0.12242 \\
\bottomrule
\end{tabular}
\caption{Traditional metrics evaluations over 60 frames (mean $\pm$ standard deviation).}
\label{tab:metrics}
\end{table*}

\begin{figure*}[ht]
\includegraphics[width=1.0\textwidth]{static/boxplots_perceptual_metrics.jpg}
\caption{Box-plots of perceptual metrics on 60 test frames. The lower, the better.}
\label{fig:metrics}
\end{figure*}

\begin{figure*}[ht]
\includegraphics[width=1.0\textwidth]{static/boxplots_traditional_metrics.jpg}
\caption{Box-plots of traditional metrics on 60 test frames. The higher, the better.}
\label{fig:metrics}
\end{figure*}

\Cref{tab:timings} shows the execution times (in seconds) of different variations of UNet and SRUNet implementations. Each table entry represents the average execution time over more than 300 executions "$\pm$" its standard deviation. SRUNet generally has faster execution times than UNet across all versions. Among the different numerical precisions, the fastest execution times are generally achieved, as expected by using INT8, followed by FP16 and FP32.

\begin{table*}[t]
\begin{tabular}{ll}
\toprule
{} &      times [s] \\
\midrule
UNet        &  0.03480 ± 0.00041 \\
UNet-FP32   &  0.01436 ± 0.00031 \\
UNet-FP16   &  0.02793 ± 0.00131 \\
UNet-INT8   &  0.02817 ± 0.00038 \\
SRUNet      &  0.01232 ± 0.00008 \\
SRUNet-FP32 &  0.00548 ± 0.00074 \\
SRUNet-FP16 &  0.00867 ± 0.00052 \\
SRUNet-INT8 &  0.00868 ± 0.00050 \\
\bottomrule
\end{tabular}
\caption{Evaluation times over 1000 runs (mean $\pm$ standard deviation).}
\label{tab:timings}
\end{table*}

\begin{figure*}[ht]
\includegraphics[width=1.0\textwidth]{static/boxplots_timings.jpg}
\caption{Average times elapsed in seconds for generating one image using different versions of UNet and SRUNet implementations.}
\label{fig:timings}
\end{figure*}

% \begin{figure*}[ht]
% \includegraphics[width=1.0\textwidth]{static/2023_03_17_barplot_vmaf_mean.png}
% \caption{Mean VMAF score on a test video using different versions of UNet and SRUNet implementations.}
% \label{fig:vmaf-mean}
% \end{figure*}
% 
% \begin{figure*}[ht]
% \includegraphics[width=1.0\textwidth]{static/2023_03_17_barplot_vmaf_harmonic_mean.png}
% \caption{Harmonic mean VMAF score on a test video using different versions of UNet and SRUNet implementations.}
% \label{fig:vmaf-harmonic-mean}
% \end{figure*}

\clearpage

\section{Qualitative Results}
\label{sec:qualitative-results}

% \begin{figure*}[ht]
% \includegraphics[width=1.0\textwidth]{static/2023_03_24_qualitative_unet.jpg}
% \caption{UNet qualitative results: (left) high-quality image; (center) generated image; (right) low-quality image.}
% \label{fig:qualitative-unet}
% \end{figure*}
% 
% \begin{figure*}[ht]
% \includegraphics[width=1.0\textwidth]{static/2023_03_24_qualitative_unet_fp32.jpg}
% \caption{UNet FP32 qualitative results: (left) high-quality image; (center) generated image; (right) low-quality image.}
% \label{fig:qualitative-unet-fp32}
% \end{figure*}
% 
% \begin{figure*}[ht]
% \includegraphics[width=1.0\textwidth]{static/2023_03_24_qualitative_unet_fp16.jpg}
% \caption{UNet FP16 qualitative results: (left) high-quality image; (center) generated image; (right) low-quality image.}
% \label{fig:qualitative-unet-fp16}
% \end{figure*}
% 
% \begin{figure*}[ht]
% \includegraphics[width=1.0\textwidth]{static/2023_03_24_qualitative_unet_int8.jpg}
% \caption{UNet INT8 qualitative results: (left) high-quality image; (center) generated image; (right) low-quality image.}
% \label{fig:qualitative-unet-int8}
% \end{figure*}
% 
% \begin{figure*}[ht]
% \includegraphics[width=1.0\textwidth]{static/2023_03_24_qualitative_srunet.jpg}
% \caption{SRUNet qualitative results: (left) high-quality image; (center) generated image; (right) low-quality image.}
% \label{fig:qualitative-srunet}
% \end{figure*}
% 
% \begin{figure*}[ht]
% \includegraphics[width=1.0\textwidth]{static/2023_03_24_qualitative_srunet_fp32.jpg}
% \caption{SRUNet FP32 qualitative results: (left) high-quality image; (center) generated image; (right) low-quality image.}
% \label{fig:qualitative-srunet-fp32}
% \end{figure*}
% 
% \begin{figure*}[ht]
% \includegraphics[width=1.0\textwidth]{static/2023_03_24_qualitative_srunet_fp16.jpg}
% \caption{SRUNet FP16 qualitative results: (left) high-quality image; (center) generated image; (right) low-quality image.}
% \label{fig:qualitative-srunet-fp16}
% \end{figure*}
% 
% \begin{figure*}[ht]
% \includegraphics[width=1.0\textwidth]{static/2023_03_24_qualitative_srunet_int8.jpg}
% \caption{SRUNet INT8 qualitative results: (left) high-quality image; (center) generated image; (right) low-quality image.}
% \label{fig:qualitative-srunet-int8}
% \end{figure*}
% 
